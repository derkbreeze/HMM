{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_corpus(path):\n",
    "    ret = []\n",
    "    with open(path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            for c in line.decode(): #python3 style\n",
    "                if c.isalpha():\n",
    "                    ret.append(c.lower())\n",
    "                if c.isspace() and ret and not ret[-1].isspace():\n",
    "                    ret.append(\" \")\n",
    "    ret = \"\".join(ret)\n",
    "    return ret.strip()\n",
    "\n",
    "def load_probabilities(path):\n",
    "    ret = None\n",
    "    with open(path, \"rb\") as f:\n",
    "        ret = pickle.load(f)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = load_corpus(\"./Brown_sample.txt\")\n",
    "p = load_probabilities(\"./prob_vector.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \n",
    "    def __init__(self, p):\n",
    "        self.pi = p[0]\n",
    "        self.a = p[1]\n",
    "        self.b = p[2]\n",
    "        \n",
    "    @staticmethod\n",
    "    def log_sum_exp(seq):\n",
    "        if abs(min(seq)) > abs(max(seq)):\n",
    "            a = min(seq)\n",
    "        else:\n",
    "            a = max(seq)\n",
    "        \n",
    "        total = 0\n",
    "        for x in seq:\n",
    "            total += np.exp(x - a)\n",
    "        return a + np.log(total)\n",
    "    \n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        N = len(self.pi)\n",
    "        alpha = []\n",
    "        \n",
    "        d1 = {}\n",
    "        for i in range(1, N+1):\n",
    "            d1[i] = self.pi[i] + self.b[i][sequence[0]]\n",
    "        alpha.append(d1)\n",
    "        \n",
    "        for t in range(1,len(sequence)):\n",
    "            d = {}\n",
    "            o = sequence[t]\n",
    "            \n",
    "            for j in range(1, N+1):\n",
    "                sum_seq = []\n",
    "                for i in range(1,N+1):\n",
    "                    sum_seq.append(alpha[-1][i] + self.a[i][j] + self.b[j][o])\n",
    "                \n",
    "                d[j] = self.log_sum_exp(sum_seq)\n",
    "            alpha.append(d)\n",
    "                    \n",
    "        return alpha\n",
    "    \n",
    "    def forward_probability(self, alpha):\n",
    "        return self.log_sum_exp(list(alpha[-1].values())) #python3 style\n",
    "    \n",
    "    def backward(self, sequence):\n",
    "        N = len(self.pi)\n",
    "        T = len(sequence)\n",
    "        \n",
    "        beta = []\n",
    "        dT = {}\n",
    "        for i in range(1,N+1):\n",
    "            dT[i] = 0 #log1 = 0\n",
    "        beta.append(dT)\n",
    "        \n",
    "        for t in range(T-2,-1,-1):\n",
    "            d = {}\n",
    "            o = sequence[t+1]\n",
    "            for i in range(1,N+1):\n",
    "                sum_seq = []\n",
    "                for j in range(1,N+1):\n",
    "                    sum_seq.append(self.a[i][j] + self.b[j][o] + beta[-1][j])\n",
    "                    \n",
    "                d[i] = self.log_sum_exp(sum_seq)\n",
    "            \n",
    "            beta.append(d)\n",
    "        \n",
    "        beta.reverse()\n",
    "            \n",
    "        return beta   \n",
    "    \n",
    "    def backward_probability(self, beta, sequence):\n",
    "        N = len(self.pi)\n",
    "        sum_seq = []\n",
    "        \n",
    "        for i in range(1,N+1):\n",
    "            sum_seq.append(self.pi[i] + self.b[i][sequence[0]] + beta[0][i])\n",
    "        return self.log_sum_exp(sum_seq)\n",
    "    \n",
    "    def xi(self, t, alpha, beta, sequence):\n",
    "        N = len(self.pi)\n",
    "        T = len(sequence)\n",
    "        \n",
    "        o = sequence[t+1]\n",
    "        xi = {}\n",
    "        sum_seq = []\n",
    "        denom = self.log_sum_exp(list(alpha[-1].values()))\n",
    "        for i in range(1,N+1):\n",
    "            xi[i] = {}\n",
    "            for j in range(1,N+1):\n",
    "                numerator = alpha[t][i] + self.a[i][j] + self.b[j][o] + beta[t+1][j]\n",
    "                xi[i][j] = numerator - denom\n",
    "                \n",
    "        return xi\n",
    "    \n",
    "    def gamma(self, t, alpha, beta, sequence):\n",
    "        N = len(self.pi)\n",
    "        T = len(sequence)\n",
    "        \n",
    "        o = sequence[t]\n",
    "        denom = self.log_sum_exp(list(alpha[-1].values()))\n",
    "        \n",
    "        gamma = {}\n",
    "        for i in range(1,N+1):\n",
    "            numerator = alpha[t][i] + beta[t][i]\n",
    "            gamma[i] = numerator - denom\n",
    "        \n",
    "        return gamma\n",
    "    \n",
    "    def forward_backward(self, sequence):\n",
    "        N = len(self.pi)\n",
    "        alpha = self.forward(sequence)\n",
    "        beta = self.backward(sequence)\n",
    "        T = len(sequence)\n",
    "        \n",
    "        xis = []\n",
    "        for t in range(T-1):\n",
    "            xis.append(self.xi(t, alpha, beta, sequence))\n",
    "        gammas = []\n",
    "        for t in range(T):\n",
    "            gammas.append(self.gamma(t, alpha, beta, sequence))\n",
    "        \n",
    "        pi_hat = gammas[0]\n",
    "        a_hat = {}\n",
    "        b_hat = {}\n",
    "        \n",
    "        for i in range(1,N+1):\n",
    "            a_hat[i] = {}\n",
    "            b_hat[i] = {}\n",
    "            \n",
    "            sum_seq = []\n",
    "            for t in range(T-1):\n",
    "                sum_seq.append(gammas[t][i])\n",
    "            a_hat_denom = self.log_sum_exp(sum_seq)\n",
    "            \n",
    "            for j in range(1,N+1):\n",
    "                sum_seq = []\n",
    "                for t in range(T-1):\n",
    "                    sum_seq.append(xis[t][i][j])\n",
    "                a_hat_num = self.log_sum_exp(sum_seq)\n",
    "                a_hat[i][j] = a_hat_num - a_hat_denom\n",
    "                \n",
    "            sum_seq = []\n",
    "            for t in range(T):\n",
    "                sum_seq.append(gammas[t][i])\n",
    "            b_hat_denom = self.log_sum_exp(sum_seq)\n",
    "            for k in self.b[i]:\n",
    "                sum_seq = []\n",
    "                for t in range(T):\n",
    "                    o = sequence[t]\n",
    "                    if o == k:\n",
    "                        sum_seq.append(gammas[t][i])\n",
    "                b_hat_num = self.log_sum_exp(sum_seq)\n",
    "                b_hat[i][k] = b_hat_num - b_hat_denom\n",
    "        \n",
    "        return (pi_hat, a_hat, b_hat)\n",
    "    \n",
    "    def update(self, sequence, cutoff_value):\n",
    "        \n",
    "        log_likelihoods = []\n",
    "        initial_log = self.forward_probability(self.forward(sequence))\n",
    "        log_likelihoods.append(initial_log)\n",
    "        increase = cutoff_value + 1\n",
    "        while (increase > cutoff_value):\n",
    "            before = self.forward_probability(self.forward(sequence))\n",
    "            new_p = self.forward_backward(sequence)\n",
    "            self.pi = new_p[0]\n",
    "            self.a = new_p[1]\n",
    "            self.b = new_p[2]\n",
    "            after = self.forward_probability(self.forward(sequence))\n",
    "            print(\"previous observation prob: {:.4f}, new observation prob: {:.4f}\".format(np.exp(before), np.exp(after)))\n",
    "            print(\"previous observation log likelihood: {:.4f}, new observation log likelihood: {:.4f}\".format(before, after))\n",
    "            increase = after - before\n",
    "            log_likelihoods.append(after)\n",
    "        return log_likelihoods, new_p\n",
    "    \n",
    "    def Viterbi(self, sequence):\n",
    "    \n",
    "        N = len(self.pi) #Number of states available\n",
    "        alpha = [] #For saving the maximum log probabilities\n",
    "        d1 = {}\n",
    "\n",
    "        for i in range(1,N+1):\n",
    "            d1[i] = h.pi[i] + h.b[i][sequence[0]] #Initialization\n",
    "        alpha.append(d1)\n",
    "\n",
    "        for t in range(1,len(sequence)-1):\n",
    "            d = {}\n",
    "            d_temp = {}\n",
    "            log_likelihoods = []\n",
    "            for i in range(1,N+1): #start state\n",
    "                d[i] = {}\n",
    "                for j in range(1,N+1): #terminal state\n",
    "                    d[i][j] = alpha[-1][i] + h.a[i][j] + h.b[j][sequence[t]]   \n",
    "\n",
    "            #Save max log likelihood ending in each state, at time t\n",
    "            for j in range(1,N+1):\n",
    "                temp = []\n",
    "                for i in range(1,N+1):\n",
    "                    temp.append(d[i][j])\n",
    "                d_temp[j] = max(temp)\n",
    "            alpha.append(d_temp)\n",
    "            \n",
    "        optimal_states = []\n",
    "        state = list(alpha[-1].values()).index(max(list(alpha[-1].values())))+1 #last optimal state\n",
    "        optimal_states.append(state)\n",
    "        for back_t in range(t, 0, -1): #start back tracing\n",
    "            #print(\"time {}\".format(back_t))\n",
    "            temp_list = []\n",
    "            for prev_state in range(1,N+1):\n",
    "                temp_list.append(alpha[back_t-1][prev_state] + h.a[prev_state][state] + h.b[state][sequence[back_t]])\n",
    "            state = temp_list.index(max(temp_list))+1\n",
    "            optimal_states.append(state)\n",
    "\n",
    "        optimal_states.reverse() #reverse the optimal hidden states so that states starts in time.\n",
    "        return optimal_states, alpha\n",
    "        #print(\"Viterbi decoding done... Optimal hidden states are: {}\".format(optimal_states))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HMM(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state probabilities before training\n",
      "0.2790602543027226\n",
      "0.35816453465344517\n",
      "0.15222317381150546\n",
      "0.21055203723232674\n",
      "state transition probabilities before training\n",
      "0.3908493040227309\n",
      "0.18938197908059773\n",
      "0.0770514911339938\n",
      "0.3427172257626776\n",
      "\n",
      "\n",
      "0.43354011383893265\n",
      "0.2089676606207099\n",
      "0.19686737445155456\n",
      "0.16062485108880287\n",
      "\n",
      "\n",
      "0.25\n",
      "0.20558981380760497\n",
      "0.22755393102410978\n",
      "0.31685625516828525\n",
      "\n",
      "\n",
      "0.40571326405494107\n",
      "0.0654317928462989\n",
      "0.2502573746425905\n",
      "0.2785975684561695\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('initial state probabilities before training')\n",
    "# for i in range(1,4+1):\n",
    "#     print(np.exp(h.pi[i]))\n",
    "# print('state transition probabilities before training')\n",
    "# for i in range(1,4+1):\n",
    "#     for j in range(1,4+1):\n",
    "#         print(np.exp(h.a[i][j]))\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -9201.3496, new observation log likelihood: -8070.9616\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8070.9616, new observation log likelihood: -8066.6165\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8066.6165, new observation log likelihood: -8060.8745\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8060.8745, new observation log likelihood: -8052.5557\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8052.5557, new observation log likelihood: -8039.7711\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8039.7711, new observation log likelihood: -8019.7449\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -8019.7449, new observation log likelihood: -7989.5433\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7989.5433, new observation log likelihood: -7949.1708\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7949.1708, new observation log likelihood: -7905.5286\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7905.5286, new observation log likelihood: -7868.4498\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7868.4498, new observation log likelihood: -7840.0893\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7840.0893, new observation log likelihood: -7815.3446\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7815.3446, new observation log likelihood: -7788.6627\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7788.6627, new observation log likelihood: -7755.4860\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7755.4860, new observation log likelihood: -7712.0608\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7712.0608, new observation log likelihood: -7657.9934\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7657.9934, new observation log likelihood: -7599.9569\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7599.9569, new observation log likelihood: -7548.9920\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7548.9920, new observation log likelihood: -7511.3173\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7511.3173, new observation log likelihood: -7485.1726\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7485.1726, new observation log likelihood: -7465.6593\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7465.6593, new observation log likelihood: -7450.3756\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7450.3756, new observation log likelihood: -7438.9592\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7438.9592, new observation log likelihood: -7429.4792\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7429.4792, new observation log likelihood: -7420.3254\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7420.3254, new observation log likelihood: -7412.2822\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7412.2822, new observation log likelihood: -7406.3956\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7406.3956, new observation log likelihood: -7402.0732\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7402.0732, new observation log likelihood: -7398.4462\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7398.4462, new observation log likelihood: -7395.3318\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7395.3318, new observation log likelihood: -7392.8362\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7392.8362, new observation log likelihood: -7390.8160\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7390.8160, new observation log likelihood: -7388.9418\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7388.9418, new observation log likelihood: -7387.0554\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7387.0554, new observation log likelihood: -7385.4098\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7385.4098, new observation log likelihood: -7384.2009\n",
      "previous observation prob: 0.0000, new observation prob: 0.0000\n",
      "previous observation log likelihood: -7384.2009, new observation log likelihood: -7383.3361\n"
     ]
    }
   ],
   "source": [
    "log_likelihoods, new_p = h.update(sequence,1) #Actually performs HMM training in an EM style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x105e416a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEcCAYAAAALEfkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107834f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(log_likelihoods)), log_likelihoods)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('log likelihood of whole observations in training HMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state probabilities after HMM training\n",
      "1.0000000000427463\n",
      "9.313898882433713e-87\n",
      "6.281161757004623e-79\n",
      "4.396126497654772e-128\n",
      "state transition probabilities after HMM training\n",
      "0.006853584490905768\n",
      "0.4599297458356615\n",
      "1.9291427866137335e-09\n",
      "0.5332166677443866\n",
      "\n",
      "\n",
      "0.012523654416700699\n",
      "0.18408775307043942\n",
      "2.559341750987588e-05\n",
      "0.8033629990952229\n",
      "\n",
      "\n",
      "0.5142080806384013\n",
      "0.0178546983404443\n",
      "0.0006834463540007576\n",
      "0.46725377466715423\n",
      "\n",
      "\n",
      "0.4673382430577756\n",
      "2.132657039354341e-06\n",
      "0.42045399921952564\n",
      "0.11220562506559045\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('initial state probabilities after HMM training')\n",
    "for i in range(1,4+1):\n",
    "    print(np.exp(h.pi[i]))\n",
    "print('state transition probabilities after HMM training')\n",
    "for i in range(1,4+1):\n",
    "    for j in range(1,4+1):\n",
    "        print(np.exp(h.a[i][j]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fulton county grand jury said friday [1, 2, 2, 4, 1, 4, 3, 1, 4, 3, 4, 1, 2, 4, 3, 1, 2, 4, 1, 2, 4, 3, 1, 4, 3, 4, 1, 2, 4, 3, 4, 4, 1, 4, 3, 1, 4, 1, 4] {1: -122.60723816850613, 2: -110.25846421561731, 3: -123.06545892472516, 4: -107.19784688875708}\n"
     ]
    }
   ],
   "source": [
    "optimal_states, alpha = h.Viterbi(sequence[:40])\n",
    "print(sequence[:40], optimal_states, alpha[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
